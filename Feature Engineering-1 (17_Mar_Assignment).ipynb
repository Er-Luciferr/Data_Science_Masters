{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cc792ed",
   "metadata": {},
   "source": [
    "## Q1: What are missing values in a dataset? Why is it essential to handle missing values? Name some algorithms that are not affected by missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8946ab",
   "metadata": {},
   "source": [
    "1. **Missing values**: Missing values in a dataset refer to the absence of data or no recorded value for a particular attribute or feature.\n",
    "2. **Handling missing values**: It is essential to handle missing values because they can affect the performance of the machine learning model and lead to inaccurate or biased results.\n",
    "3. **Algorithms not affected by missing values**: Some algorithms that can handle missing data without requiring imputation include k-Nearest Neighbors, Random Forest, and Naive Bayes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9467b6",
   "metadata": {},
   "source": [
    "## Q2: List down techniques used to handle missing data. Give an example of each with python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5caa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Imputation\n",
    "import pandas as pd\n",
    "df = pd.read_csv('data.csv')\n",
    "df = df.fillna(df.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0140e16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mode Imputation\n",
    "import pandas as pd\n",
    "df = pd.read_csv('data.csv')\n",
    "df = df.fillna(df.mode())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c36219a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median Imputation\n",
    "import pandas as pd\n",
    "df = pd.read_csv('data.csv')\n",
    "df = df.fillna(df.median())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597cd27f",
   "metadata": {},
   "source": [
    "## Q3: Explain the imbalanced data. What will happen if imbalanced data is not handled?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57580837",
   "metadata": {},
   "source": [
    "Imbalanced data refers to a situation where the classes in the target variable are not represented equally. If imbalanced data is not handled, the machine learning model may be biased towards the majority class and may not perform well on the minority class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7119e3",
   "metadata": {},
   "source": [
    "## Q4: What are Up-sampling and Down-sampling? Explain with an example when up-sampling and down-sampling are required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896ed4f1",
   "metadata": {},
   "source": [
    "Up-sampling and down-sampling are techniques used to balance imbalanced data in a dataset. Up-sampling involves increasing the number of samples in the minority class, while down-sampling involves decreasing the number of samples in the majority class.\n",
    "\n",
    "For example, let's say we have a dataset with two classes: Class A and Class B. Class A has 1000 samples, while Class B has only 100 samples. This is an imbalanced dataset, as Class A has significantly more samples than Class B.\n",
    "\n",
    "To balance this dataset, we could use up-sampling to increase the number of samples in Class B. This could be done by randomly duplicating samples from Class B until it has the same number of samples as Class A. Alternatively, we could use down-sampling to decrease the number of samples in Class A. This could be done by randomly removing samples from Class A until it has the same number of samples as Class B.\n",
    "\n",
    "Up-sampling and down-sampling are required when dealing with imbalanced data, as they can help improve the performance of machine learning models by ensuring that all classes are represented equally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e13680",
   "metadata": {},
   "source": [
    "## Q5: What is data Augmentation? Explain SMOTE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080f77f0",
   "metadata": {},
   "source": [
    "Data augmentation is a technique used to increase the amount of training data by creating new samples from the existing data. This is done by applying various transformations to the original data, such as rotation, scaling, and flipping, to generate new samples that are similar but not identical to the original data.\n",
    "\n",
    "SMOTE (Synthetic Minority Over-sampling Technique) is a specific data augmentation technique used to balance imbalanced datasets. It works by creating synthetic samples of the minority class by interpolating between existing minority class samples. This helps to increase the number of samples in the minority class and balance the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34006838",
   "metadata": {},
   "source": [
    "## Q6: What are outliers in a dataset? Why is it essential to handle outliers?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ef8cbc",
   "metadata": {},
   "source": [
    "Outliers are data points in a dataset that are significantly different from the other data points. They can be caused by various factors, such as measurement errors, data entry errors, or natural variability in the data.\n",
    "\n",
    "It is essential to handle outliers because they can have a significant impact on the analysis of the data. Outliers can affect the mean, median, and standard deviation of the data, which can lead to inaccurate or misleading results. They can also affect the performance of machine learning models, as they can cause the model to overfit to the outlier data and perform poorly on new data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368a59b0",
   "metadata": {},
   "source": [
    "## Q7: You are working on a project that requires analyzing customer data. However, you notice that some of the data is missing. What are some techniques you can use to handle the missing data in your analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f224dae5",
   "metadata": {},
   "source": [
    " 1) Mean Imputation\n",
    " \n",
    " 2) Median Impution\n",
    " \n",
    " 3) Mode Imputation\n",
    " \n",
    " 4) Listwise Deletion (if dataset is large)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351698df",
   "metadata": {},
   "source": [
    "## Q8: You are working with a large dataset and find that a small percentage of the data is missing. What are some strategies you can use to determine if the missing data is missing at random or if there is a pattern to the missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1002411f",
   "metadata": {},
   "source": [
    "There are several strategies that can be used to determine if missing data is missing at random or if there is a pattern to the missing data. Some of these strategies include:\n",
    "\n",
    "1. **Visual inspection**: Plotting the data and visually inspecting it for patterns can help identify if the missing data is missing at random or not.\n",
    "2. **Statistical tests**: Conducting statistical tests, such as chi-squared tests or t-tests, can help determine if the missing data is missing at random or not.\n",
    "3. **Missing data mechanisms**: Understanding the mechanisms that cause data to be missing, such as data entry errors or survey non-response, can help determine if the missing data is missing at random or not.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7bf9ae",
   "metadata": {},
   "source": [
    "## Q9: Suppose you are working on a medical diagnosis project and find that the majority of patients in the dataset do not have the condition of interest, while a small percentage do. What are some strategies you can use to evaluate the performance of your machine learning model on this imbalanced dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bebfe8",
   "metadata": {},
   "source": [
    "When working with an imbalanced dataset, such as in a medical diagnosis project where the majority of patients do not have the condition of interest, it is important to use appropriate evaluation metrics to assess the performance of the machine learning model. Some strategies that can be used include:\n",
    "\n",
    "1. **Confusion matrix**: A confusion matrix can help visualize the performance of the model by showing the number of true positives, false positives, true negatives, and false negatives.\n",
    "2. **Precision, recall, and F1 score**: Precision measures the proportion of true positive predictions among all positive predictions, while recall measures the proportion of true positive predictions among all actual positives. The F1 score is the harmonic mean of precision and recall and provides a balanced measure of the model's performance.\n",
    "3. **ROC curve and AUC**: The receiver operating characteristic (ROC) curve plots the true positive rate against the false positive rate at different classification thresholds, while the area under the curve (AUC) provides a measure of the model's ability to distinguish between the two classes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119988ce",
   "metadata": {},
   "source": [
    "## Q10: When attempting to estimate customer satisfaction for a project, you discover that the dataset is unbalanced, with the bulk of customers reporting being satisfied. What methods can you employ to balance the dataset and down-sample the majority class?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fa84d1",
   "metadata": {},
   "source": [
    "1) Downsampling Technique (down sample the majority class)\n",
    "\n",
    "from sklearn.utlis import resample\n",
    "\n",
    "2) SMOTE (down sample the majority class by reducing the weights parameter)\n",
    "\n",
    "from imblearn.oversampling import SMOTE\n",
    "<br>downsample = SMOTE()\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cee0e84",
   "metadata": {},
   "source": [
    "## Q11: You discover that the dataset is unbalanced with a low percentage of occurrences while working on a project that requires you to estimate the occurrence of a rare event. What methods can you employ to balance the dataset and up-sample the minority class?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea462bf9",
   "metadata": {},
   "source": [
    "1) SMOTE (up-sample the minority class by increasing the weights parameter)\n",
    "\n",
    "from imblearn.oversampling import SMOTE\n",
    "<br>downsample = SMOTE()\n",
    "\n",
    "2) Upsampling Technique (Up-sample the minority class)\n",
    "\n",
    "from sklearn.utlis import resample\n",
    " \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
